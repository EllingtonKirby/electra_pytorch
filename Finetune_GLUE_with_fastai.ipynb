{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uns2VbU0Yj5f"
   },
   "outputs": [],
   "source": [
    "try: import nlp\n",
    "except ImportError: \n",
    "  %pip install -q nlp\n",
    "  exit() # In Colab, to use the newer installed pyarrow, you need to restart your session for first use\n",
    "try: import fastai2\n",
    "except ImportError: \n",
    "  !git clone https://github.com/fastai/fastai2\n",
    "  %cd fastai2\n",
    "  %pip install -qe \".[dev]\"\n",
    "  %cd .. \n",
    "try: import transformers\n",
    "except ImportError: \n",
    "  %pip install -q transformers\n",
    "try: import _utils\n",
    "except ImportError: \n",
    "  !git clone https://github.com/richardyy1188/Pretrain-MLM-and-finetune-on-GLUE-with-fastai.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "ugFdx5v_YxzA",
    "outputId": "e6663d66-4c4b-4953-8388-7fa2b23b126a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'Pretrain-MLM-and-finetune-on-GLUE-with-fastai'\n",
      "/content/Pretrain-MLM-and-finetune-on-GLUE-with-fastai\n"
     ]
    }
   ],
   "source": [
    "%cd Pretrain-MLM-and-finetune-on-GLUE-with-fastai\n",
    "\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from IPython.core.debugger import set_trace as bk\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import nlp\n",
    "from transformers import ElectraModel, ElectraTokenizer, ElectraTokenizerFast\n",
    "from fastai2.text.all import *\n",
    "from _utils.would_like_to_pr import *\n",
    "from _utils.hf_integration import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6wb0zB6iYyvC"
   },
   "outputs": [],
   "source": [
    "\"\"\" tokenizer and fast tokenizer\n",
    "We use normal tokenizer to get vocab, use fast tokenizer to convert tokens to ids.\n",
    "Because we can't get vocab from fast tokenizer and fast tokenizer is faster,\n",
    "and they share the same token-id mapping.\n",
    "\"\"\"\n",
    "hf_tokenizer = ElectraTokenizer.from_pretrained(\"google/electra-small-discriminator\")\n",
    "hf_fast_tokenizer = ElectraTokenizerFast.from_pretrained(\"google/electra-small-discriminator\")\n",
    "base_model = ElectraModel.from_pretrained('google/electra-small-discriminator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yoI6QffPY6Jv"
   },
   "source": [
    "# 1. Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p_P8P4hffUr8"
   },
   "source": [
    "## 1.1 Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W0zfrnOzY9u6"
   },
   "source": [
    "**Download, Preprocess, and Cache**\n",
    "\n",
    "In Colab, it takes you 20+ minutes for the first time, and seconds for subsequent calls. \n",
    "\n",
    "It will cost serveral minutes if you reset runtime even load the cache, but it's not true when you just restart the runtime. So I guess they may keep someth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "ae0863b074ff4a1a959514881fe2802f",
      "e5d5d86746ec4e2298028c57ef775d84",
      "a8b32129b9ab41d0895cb1ec445db9ca",
      "2d26c89a3d97493e911c52fa20cf79d9",
      "65eee3543a9d46adbc8037995c3a69a0",
      "9fc29a98d6be46e0974d1f0f7681d5c3",
      "5b8f1e5172204ed58bd60972289b24a8",
      "bd8da3c0b2784f2094d3b0cfa744cf87",
      "f74af04bf4764b7888f0a45e37ce85c1",
      "f35afd9d13c240aba4e0619cca0199b7",
      "a07124360f4c4249a745891d83e719f6",
      "f26a4f6d9334465d9022ab2a3401035b",
      "007556af2af8413ca47aa5f7f725e68a",
      "8d4771f53c7046f1afe7e04a3a647a31",
      "71beed6de71c4aa2862ef33e21cc58bc",
      "e1d8bdd9c1a74bc18a103bc900589c2c"
     ]
    },
    "colab_type": "code",
    "id": "U-PLcDIRY6y-",
    "outputId": "12e31f13-b70f-48c8-dd45-c6f1718b03c1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae0863b074ff4a1a959514881fe2802f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28998.0, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74af04bf4764b7888f0a45e37ce85c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=30329.0, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loading processed datasets of cola ...\n",
      "loading processed datasets of sst2 ...\n",
      "loading processed datasets of mrpc ...\n",
      "loading processed datasets of qqp ...\n",
      "loading processed datasets of stsb ...\n",
      "loading processed datasets of mnli ...\n",
      "loading processed datasets of qnli ...\n",
      "loading processed datasets of rte ...\n",
      "loading processed datasets of wnli ...\n",
      "loading processed datasets of ax ...\n"
     ]
    }
   ],
   "source": [
    "# create a 'glue' folder under it, and all cache files will be under 'glue'\n",
    "cache_dir=Path('/content/drive/My Drive/datasets')\n",
    "cache_dir.mkdir(parents=True, exist_ok=True) # create recursively if not exist\n",
    "\n",
    "def textcols(dataset):\n",
    "  \"Infer text cols of different GLUE datasets in huggingface/nlp\"\n",
    "  column_names = dataset.column_names\n",
    "  if 'question' in column_names: return ['question', 'sentence']\n",
    "  elif 'sentence1' in column_names: return ['sentence1', 'sentence2']\n",
    "  elif 'question1' in column_names: return ['question1','question2']\n",
    "  elif 'premise' in column_names: return ['premise','hypothesis']\n",
    "  elif 'sentence' in column_names: return ['sentence']\n",
    "\n",
    "\"\"\"\n",
    "quote from transformers tutorial of fastai (http://dev.fast.ai/tutorial.transformers)\n",
    "we don't use the tokenizer.encode method since it does some additional preprocessing for the model after tokenizing and numericalizing (the aprt throwing a warning before). Here we don't need any post-processing so it's fine to skip it.\n",
    "\"\"\"\n",
    "def tokenize_sents(example, cols):\n",
    "  if len(cols)==1:\n",
    "    example['input_ids'] = hf_fast_tokenizer.convert_tokens_to_ids(hf_fast_tokenizer.tokenize(f\"[CLS] {example[cols[0]]} [SEP]\"))\n",
    "  elif len(cols)==2:\n",
    "    example['input_ids'] = concat(hf_fast_tokenizer.convert_tokens_to_ids(hf_fast_tokenizer.tokenize(f'[CLS] {example[cols[0]]} [SEP]')),\n",
    "                                  hf_fast_tokenizer.convert_tokens_to_ids(hf_fast_tokenizer.tokenize(f'{example[cols[1]]} [SEP]')))\n",
    "  else: raise ValueError()\n",
    "  return example\n",
    "\n",
    "glue_dsets = {}\n",
    "for glue_task in ['cola', 'sst2', 'mrpc', 'qqp', 'stsb', 'mnli', 'qnli', 'rte', 'wnli', 'ax']:\n",
    "  task = nlp.load_dataset('glue', glue_task, cache_dir=cache_dir)\n",
    "  glue_dsets[glue_task] = {}\n",
    "  print(f'loading processed datasets of {glue_task} ...')\n",
    "  for split in task.keys():\n",
    "    raw_dataset = task[split]\n",
    "    cache_file = Path(raw_dataset.cache_files[0]['filename']).parent / f'tokenized_{split}.arrow'\n",
    "    if cache_file.exists():dataset = nlp.Dataset.from_file(str(cache_file))\n",
    "    else: dataset = raw_dataset.map(partial(tokenize_sents, cols=textcols(raw_dataset)),\n",
    "                                    cache_file_name=str(cache_file))\n",
    "    glue_dsets[glue_task][split] = dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yKxetBkqfdgm"
   },
   "source": [
    "## 1.2 hf/hlp datasets -> fastai dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Oc3ZjYwZGLn"
   },
   "outputs": [],
   "source": [
    "# I don't know how to let `Learner` validate two validation sets every epochs, so I just merged `mnli validation mismatched` and `mnli validation matched`.\n",
    "glue_dsets['mnli']['validation'] = HF_MergedDataset(glue_dsets['mnli']['validation_matched'], glue_dsets['mnli']['validation_mismatched'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R4mAI-scZSQh"
   },
   "outputs": [],
   "source": [
    "def text_decode_fc(x, pretty=True):\n",
    "  if pretty:\n",
    "    return hf_fast_tokenizer.decode([idx for idx in x if idx != hf_fast_tokenizer.pad_token_id])\n",
    "  else:\n",
    "    tokens = hf_fast_tokenizer.convert_ids_to_tokens(x)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "@delegates(FilteredBase.dataloaders)\n",
    "def get_glue_dls(task_name, **kwargs):\n",
    "  assert task_name in ['cola', 'sst2', 'mrpc', 'qqp', 'stsb', 'mnli', 'qnli', 'rte', 'wnli', 'ax']\n",
    "  splits = ['train','validation']+(['test'] if task_name != 'mnli' else ['test_matched', 'test_mismatched'])\n",
    "  if task_name == 'ax': splits = ['test']\n",
    "  arrow_dsets = [glue_dsets[task_name][s] for s in splits ]\n",
    "  show_pretty = kwargs.pop('show_pretty', True) \n",
    "  dsets = HF_Datasets(datasets=arrow_dsets, \n",
    "                      cols=['input_ids', 'label'],\n",
    "                      encode_types=[TensorText, noop],\n",
    "                      decode_funcs=[partial(text_decode_fc,pretty=show_pretty),noop],\n",
    "                      decode_types=[TitledStr, lambda x: Category(x.item())])\n",
    "  dl_cache_files = [Path(dset.cache_files[0]['filename']).parent/f'dl_{s}.pth' for dset, s in zip(dsets,splits)]\n",
    "  if all([ p.exists() for p in dl_cache_files]):\n",
    "    device = kwargs.pop('device', default_device())\n",
    "    dl_s = [TextDataloader.from_cache(f, dsets[i], bs=32, **kwargs) for i, f in enumerate(dl_cache_files)]  \n",
    "    dls = DataLoaders(*dl_s, device=device)\n",
    "  else:\n",
    "    dls = dsets.dataloaders(before_batch=partial(pad_input_chunk,pad_first=False,pad_idx=hf_fast_tokenizer.pad_token_id,),\n",
    "                             dl_type=partial(TextDataloader, sort_by_len=False),\n",
    "                            bs=32,\n",
    "                             **kwargs)\n",
    "    for dl, cache_f in zip(dls,dl_cache_files): dl.cache(cache_f)\n",
    "  return dls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MqtDnxK9ZYQP"
   },
   "source": [
    "## 1.3 Get dataloaders fror each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0VYQubDaZbRv"
   },
   "source": [
    "**[CoLA](https://nyu-mll.github.io/CoLA/)** (*The Corpus of Linguistic Acceptability*):\n",
    "\n",
    "\n",
    "Check whether a sentence is linguistically acceptable. \n",
    "\n",
    "(0: unacceptable, 1: acceptable) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "HhZ3HD7VZalK",
    "outputId": "7ea5edbf-6a70-4f5a-9b85-c033e7aef666"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size (train/valid/test): 8551/1043/1063\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] our friends won't buy this analysis, let alone the next one we propose. [SEP]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] one more pseudo generalization and i'm giving up. [SEP]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cola_dls = get_glue_dls('cola', show_bar=False)\n",
    "print(f\"Dataset size (train/valid/test): {len(cola_dls[0].dataset)}/{len(cola_dls[1].dataset)}/{len(cola_dls[2].dataset)}\")\n",
    "cola_dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ZJ2zGxJZiyq"
   },
   "source": [
    "**Note**: for the readibility, we won't show pad and result of sentencepiece ('##...') here, which are the actual results in a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "j1zl6tm6Zk02",
    "outputId": "e6212d7a-b03b-41c4-ac46-e8a7633ad4be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] our friends won ' t buy this analysis , let alone the next one we propose . [SEP]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] one more pseudo general ##ization and i ' m giving up . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_glue_dls('cola', show_bar=False, show_pretty=False).show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "STiSJYdbZns1"
   },
   "source": [
    "**[SST-2](https://nlp.stanford.edu/sentiment/index.html)** (*The Stanford Sentiment Treebank*): \n",
    "\n",
    "Identify the sentiment of a work/phrase/sentence. \n",
    "\n",
    "(1: positvie, 0: negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "ouo5jT9sZnKG",
    "outputId": "ef107490-d6b8-4551-9028-33cc299fc674"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size (train/valid/test): 67349/872/1821\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] hide new secretions from the parental units [SEP]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] contains no wit, only labored gags [SEP]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sst2_dls = get_glue_dls('sst2')\n",
    "print(f\"Dataset size (train/valid/test): {len(sst2_dls[0].dataset)}/{len(sst2_dls[1].dataset)}/{len(sst2_dls[2].dataset)}\")\n",
    "sst2_dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wecP4wm0ZqfX"
   },
   "source": [
    "**[MRPC](https://www.microsoft.com/en-us/download/details.aspx?id=52398)** (*Microsoft Research Paraphrase Corpus*): \n",
    "\n",
    "Whether each pair captures a paraphrase/semantic equivalence relationship. \n",
    "\n",
    "(1: yes, 0: no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "6T54EE4WZxgW",
    "outputId": "98e94bdb-324d-4d80-b367-7f4f6da2efb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size (train/valid/test): 67349/872/57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] amrozi accused his brother, whom he called \" the witness \", of deliberately distorting his evidence. [SEP] referring to him as only \" the witness \", amrozi accused his brother of deliberately distorting his evidence. [SEP]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] yucaipa owned dominick's before selling the chain to safeway in 1998 for $ 2. 5 billion. [SEP] yucaipa bought dominick's in 1995 for $ 693 million and sold it to safeway for $ 1. 8 billion in 1998. [SEP]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mrpc_dls = get_glue_dls('mrpc',show_bar=False)\n",
    "print(f\"Dataset size (train/valid/test): {len(sst2_dls.train_ds)}/{len(sst2_dls.valid_ds)}/{len(sst2_dls[2])}\")\n",
    "mrpc_dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "znmNswfyZuCb"
   },
   "source": [
    "**[STS-B](http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark)** (*Semantic Textual Similarity Benchmark*):\n",
    "\n",
    "Score the similarity of meanings of two sentences. The only regression task in GLUE \n",
    "\n",
    "(0.0 ~ 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "631vsrFwaDHB",
    "outputId": "380a5db6-b00b-49aa-a5d7-7d4cedba576e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size (train/valid/test): 5749/1500/44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] a plane is taking off. [SEP] an air plane is taking off. [SEP]</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] a man is playing a large flute. [SEP] a man is playing a flute. [SEP]</td>\n",
       "      <td>3.799999952316284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stsb_dls = get_glue_dls('stsb',show_bar=False)\n",
    "print(f\"Dataset size (train/valid/test): {len(stsb_dls.train_ds)}/{len(stsb_dls.valid_ds)}/{len(stsb_dls[2])}\")\n",
    "stsb_dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YR_ok10uaCYM"
   },
   "source": [
    "**[QQP](https://www.quora.com/q/quoradata/First-Quora-Dataset-Release-Question-Pairs)** (*Quora Question Pairs*)\n",
    "\n",
    "Check whether two questions are duplicated. \n",
    "\n",
    "(0: no, 1: duplicated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "hWQc8402aFJb",
    "outputId": "8a4e6617-47e4-4a92-bc56-481730a16088"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size (train/valid/test): 363849/40430/12218\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] how is the life of a math student? could you describe your own experiences? [SEP] which level of prepration is enough for the exam jlpt5? [SEP]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] how do i control my horny emotions? [SEP] how do you control your horniness? [SEP]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "qqp_dls = get_glue_dls('qqp')\n",
    "print(f\"Dataset size (train/valid/test): {len(qqp_dls.train_ds)}/{len(qqp_dls.valid_ds)}/{len(qqp_dls[2])}\")\n",
    "qqp_dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dnZm1zqEaHHB"
   },
   "source": [
    "**[MNLI](https://cims.nyu.edu/~sbowman/multinli/)** (*The Multi-Genre NLI Corpus*)\n",
    "\n",
    "Whether the premise (sentence 1) entails the hypothesis (sentence 2) (entailment), contradicts the hypothesis (contradiction), or neither (neutral) \n",
    "\n",
    "(0: entailment, 1: neutral, 2: contradiction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "3PRuXBJ8aJTH",
    "outputId": "89fd1479-796c-43ef-ee71-292ac6ed4bad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size (train/valid/test_matched/test_mismatched): 392702/19647/9796/9847\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] conceptually cream skimming has two basic dimensions - product and geography. [SEP] product and geography are what make cream skimming work. [SEP]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] you know during the season and i guess at at your level uh you lose them to the next level if if they decide to recall the the parent team the braves decide to call to recall a guy from triple a then a double a guy goes up to replace him and a single a guy goes up to replace him [SEP] you lose the things to the following level if the people recall. [SEP]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnli_dls = get_glue_dls('mnli')\n",
    "print(f\"Dataset size (train/valid/test_matched/test_mismatched): {len(mnli_dls[0].dataset)}/{len(mnli_dls[1].dataset)}/{len(mnli_dls[2].dataset)}/{len(mnli_dls[3].dataset)}\")\n",
    "mnli_dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PJKg-BSkaPN5"
   },
   "source": [
    "**QNLI** (*The Stanford Question Answering Dataset*):\n",
    "\n",
    "The task is to determine whether the context sentence (sentence 2) contains the answer to the question (sentence 1).\n",
    "\n",
    "(0: entailment, 1: not_entailment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "DIK9BAnBaLbj",
    "outputId": "62ee8573-b4f6-4274-9592-44920c010674"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size (train/valid/test): 104743/5463/5463\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] when did the third digimon series begin? [SEP] unlike the two seasons before it and most of the seasons that followed, digimon tamers takes a darker and more realistic approach to its story featuring digimon who don't reincarnate after their deaths and more complex character development in the original japanese. [SEP]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] which missile batteries often have individual launchers several kilometres from one another? [SEP] when manpads is operated by specialists, batteries may have several dozen teams deploying separately in small sections ; self - propelled air defence guns may deploy in pairs. [SEP]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "qnli_dls = get_glue_dls('qnli')\n",
    "print(f\"Dataset size (train/valid/test): {len(qnli_dls[0].dataset)}/{len(qnli_dls[1].dataset)}/{len(qnli_dls[2].dataset)}\")\n",
    "qnli_dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I2OPdiDpaS6v"
   },
   "source": [
    "**[RTE](https://aclweb.org/aclwiki/Recognizing_Textual_Entailment)** (*Recognizing_Textual_Entailment*):\n",
    "\n",
    "Whether hypothesis (sentence 2) is entailed (can be inferred) from the premise (sentence 1).\n",
    "\n",
    "(0: entailment, 1: not_entailment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "cODdx4WyaVRh",
    "outputId": "ee44b782-8da0-42a8-ef6f-b17a841679df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size (train/valid/test): 2490/277/3000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] no weapons of mass destruction found in iraq yet. [SEP] weapons of mass destruction found in iraq. [SEP]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] a place of sorrow, after pope john paul ii died, became a place of celebration, as roman catholic faithful gathered in downtown chicago to mark the installation of new pope benedict xvi. [SEP] pope benedict xvi is the new leader of the roman catholic church. [SEP]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rte_dls = get_glue_dls('rte', show_bar=False)\n",
    "print(f\"Dataset size (train/valid/test): {len(rte_dls[0].dataset)}/{len(rte_dls[1].dataset)}/{len(rte_dls[2].dataset)}\")\n",
    "rte_dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E-iIX2EaaUt-"
   },
   "source": [
    "**[WNLI](https://cs.nyu.edu/faculty/davise/papers/WinogradSchemas/WS.html)** (*The Winograd Schema Challenge*)\n",
    "\n",
    "Check whether sentence 2 (which is rephrased sentence of sentence 1) correctly solve the pronoun in sentence 1.\n",
    "\n",
    "(0: wrong, 1: correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "L7wGvrihaZAj",
    "outputId": "df1fad6b-d779-4fe9-f9c8-53bacf5eec07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size (train/valid/test): 635/71/146\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] i stuck a pin through a carrot. when i pulled the pin out, it had a hole. [SEP] the carrot had a hole. [SEP]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] john couldn't see the stage with billy in front of him because he is so short. [SEP] john is so short. [SEP]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wnli_dls = get_glue_dls('wnli', show_bar=False)\n",
    "print(f\"Dataset size (train/valid/test): {len(wnli_dls[0].dataset)}/{len(wnli_dls[1].dataset)}/{len(wnli_dls[2].dataset)}\")\n",
    "wnli_dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0RQ-BEaIaa8F"
   },
   "source": [
    "**[AX](https://gluebenchmark.com/diagnostics)** (*GLUE Diagnostic Dataset*):\n",
    "\n",
    "Whether the premise (sentence 1) entails the hypothesis (sentence 2) (entailment), contradicts the hypothesis (contradiction), or neither (neutral) \n",
    "\n",
    "Test set only.\n",
    "\n",
    "The label is all -1, because this is a test dataset and the answers is kept by GLUE benchmark and not provided. The categories are the same as MNLI (entailment, neutral, contradiction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "5IKH0iJKadAW",
    "outputId": "0c5935c4-608f-426e-f3d0-9d380df14fa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size (test): 1104\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] the cat sat on the mat. [SEP] the cat did not sit on the mat. [SEP]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] the cat did not sit on the mat. [SEP] the cat sat on the mat. [SEP]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax_dls = get_glue_dls('ax')\n",
    "print(f\"Dataset size (test): {len(ax_dls[0].dataset)}\")\n",
    "ax_dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3wRQS_H1aekI"
   },
   "outputs": [],
   "source": [
    "glue_dls = {}\n",
    "for task_name in ['cola', 'sst2', 'mrpc', 'qqp', 'stsb', 'mnli', 'qnli', 'rte', 'wnli', 'ax']:\n",
    "  dls = eval(f\"{task_name}_dls\")\n",
    "  if task_name != 'ax':\n",
    "    dls[0].desc_sort(); dls[1].desc_sort(); # sort by len to reduce pad, but not for test_dl which keep the order of sample to let us add the dataset idx conveniently later \n",
    "  glue_dls[task_name] = dls\n",
    "glue_dls['ax'][0].shuffle = False # fastai see 0th dl as train_dl which is default shuffled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LFcM5MGaafFJ"
   },
   "source": [
    "# 2. Finetuning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tUGxkcDfQGxS"
   },
   "source": [
    "* ELECTRA use CLS encodings as pooled result to predict the sentence. (see [here](https://github.com/google-research/electra/blob/79111328070e491b287c307906701ebc61091eb2/model/modeling.py#L254) of its official repository)\n",
    "\n",
    "* Note that we should use different prediction head for different tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MF6vajgKQKJ7"
   },
   "outputs": [],
   "source": [
    "class SentencePredictHead(nn.Module):\n",
    "  \"The way that Electra and Bert do for sentence prediction task\"\n",
    "  def __init__(self, hidden_size, targ_voc_size):\n",
    "    super().__init__()\n",
    "    self.linear = nn.Linear(hidden_size, targ_voc_size)\n",
    "    self.dropout = nn.Dropout(0.1)\n",
    "  def forward(self, x):\n",
    "    \"x: (batch size, sequence length, hidden_size)\"\n",
    "    return self.linear(self.dropout(x[:,0])) # project the first token (a special token)'s hidden encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hRoFPXjpe4Nb"
   },
   "source": [
    "`SentencePredictHead`\n",
    "* change `targ_voc_size` for diffrent task\n",
    "* change `256` for your model's hidden size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "K3_2P-uZV8sb",
    "outputId": "f114b91b-c088-4192-a193-128ede97721b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([1, 13]) (batch size, sequence length)\n",
      "output shape: torch.Size([1, 2]) (batch_size, target vocab size)\n",
      "The output is the raw score-like thing for each label\n",
      "tensor([[ 0.1295, -0.3478]])\n"
     ]
    }
   ],
   "source": [
    "single_task_model = nn.Sequential(HF_ModelWrapper(base_model, pad_id=hf_tokenizer.pad_token_id, sep_id=hf_tokenizer.sep_token_id), # specify spe_id and wrapper will create and pass token_type_ids of sentece A/B for you\n",
    "                                  SentencePredictHead(256, targ_voc_size=2)) # <- change targ_voc_size according to the task\n",
    "inp_tensor = torch.tensor(hf_tokenizer.encode('I am the sentence A','I am the sentence B'))[None,:] \n",
    "print(f'input shape: {inp_tensor.shape} (batch size, sequence length)')\n",
    "with torch.no_grad(): out_tensor = single_task_model(inp_tensor)\n",
    "print(f'output shape: {out_tensor.shape} (batch_size, target vocab size)')\n",
    "print(f'The output is the raw score-like thing for each label')\n",
    "print(out_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zi5_OKHqX8qw"
   },
   "source": [
    "# 3. Single Task Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "poNJYRwETtBo"
   },
   "source": [
    "## 3.1 Discriminative learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7OyT-hy-7FXz"
   },
   "outputs": [],
   "source": [
    "# Names come from, for nm in model.named_modules(): print(nm[0])\n",
    "def hf_electra_param_splitter(model, num_hidden_layers, outlayer_name):\n",
    "  names = ['model.embeddings', *[f'model.encoder.layer.{i}' for i in range(num_hidden_layers)], outlayer_name]\n",
    "  def endswith_any(n,ns): return any([ n.endswith(suffix) for suffix in ns])\n",
    "  groups = [ list(mod.parameters()) for name, mod in model.named_modules() if endswith_any(name, names) ]\n",
    "  assert len(groups) == len(names)\n",
    "  return groups\n",
    "\n",
    "def get_layer_lrs(lr, decay_rate_of_depth, num_hidden_layers):\n",
    "  # I think input layer as bottom and output layer as top, which make 'depth' mean different from the one of official repo \n",
    "  return [ lr * (decay_rate_of_depth ** depth) for depth in reversed(range(num_hidden_layers+2))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N2ug-bscA9gC"
   },
   "source": [
    "## 3.2 Learning rate schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nzqFhWQkBGhu"
   },
   "outputs": [],
   "source": [
    "def linear_warmup_and_decay(pct_now, lr_max, end_lr, decay_power, warmup_pct, total_steps):\n",
    "  \"\"\"\n",
    "  end_lr: the end learning rate for linear decay\n",
    "  warmup_pct: percentage of training steps to for linear increase\n",
    "  pct_now: percentage of traning steps we have gone through, notice pct_now=0.0 when calculating lr for first batch.\n",
    "  \"\"\"\n",
    "  \"\"\"\n",
    "  pct updated after_batch, but global_step (in tf) seems to update before optimizer step,\n",
    "  so pct is actually (global_step -1)/total_steps \n",
    "  \"\"\"\n",
    "  fixed_pct_now = pct_now + 1/total_steps\n",
    "  \"\"\"\n",
    "  According to source code of the official repository, it seems they merged two lr schedule (warmup and linear decay)\n",
    "  sequentially, instead of split training into two phases for each, this might because they think when in the early\n",
    "  phase of training, pct is low, and thus the decaying formula makes little difference to lr.\n",
    "  \"\"\"\n",
    "  decayed_lr = (lr_max-end_lr) * (1-fixed_pct_now)**decay_power + end_lr # https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/polynomial_decay\n",
    "  warmed_lr = decayed_lr * min(1.0, fixed_pct_now / warmup_pct) # https://github.com/google-research/electra/blob/81f7e5fc98b0ad8bfd20b641aa8bc9e6ac00c8eb/model/optimization.py#L44\n",
    "  return warmed_lr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Mcjq0b8wbkO"
   },
   "source": [
    "## 3.3 finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZLKItnWAd0a3"
   },
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "dls = glue_dls['mrpc']\n",
    "\n",
    "layer_lrs = get_layer_lrs(lr=3e-4,\n",
    "                          decay_rate_of_depth=0.8,\n",
    "                          num_hidden_layers=base_model.config.num_hidden_layers)\n",
    "\n",
    "lr_shedule = ParamScheduler({'lr': partial(linear_warmup_and_decay,\n",
    "                                            lr_max=np.array(layer_lrs),\n",
    "                                            end_lr=0.0,\n",
    "                                            decay_power=1,\n",
    "                                            warmup_pct=0.1,\n",
    "                                            total_steps=num_epochs*(len(dls.train)))})\n",
    "\n",
    "single_task_learn = Learner(dls, single_task_model,\n",
    "                            # flatten only if needed, here in fact we don't need\n",
    "                            # if regression task (STS-B), use MSELossFlat() instead\n",
    "                            loss_func=CrossEntropyLossFlat(), \n",
    "                            opt_func=partial(Adam, eps=1e-6,),\n",
    "                            metrics=[F1Score(), Accuracy()],\n",
    "                            splitter=partial(hf_electra_param_splitter, \n",
    "                                             num_hidden_layers=base_model.config.num_hidden_layers, \n",
    "                                             outlayer_name='1'),\n",
    "                            #lr=layer_lrs,\n",
    "                            )#.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "iy6g3alOACMv",
    "outputId": "11aa5215-4f54-485e-85d6-35eb8233458c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.515391</td>\n",
       "      <td>0.372465</td>\n",
       "      <td>0.878403</td>\n",
       "      <td>0.835784</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.348412</td>\n",
       "      <td>0.444597</td>\n",
       "      <td>0.890675</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.230610</td>\n",
       "      <td>0.312393</td>\n",
       "      <td>0.903678</td>\n",
       "      <td>0.865196</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "single_task_learn.fit(n_epoch=num_epochs,\n",
    "                      cbs=[lr_shedule])\n",
    "single_task_learn.recorder.plot_sched() # print last lr of last paramters groups (output layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c73X4fdrmnlP"
   },
   "source": [
    "## 3.3 Predict the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EYMsFM0Cmp1k"
   },
   "outputs": [],
   "source": [
    "test_pred_dir = cache_dir/'glue'/'test'\n",
    "test_pred_dir.mkdir(exist_ok=True)\n",
    "preds = single_task_learn.get_preds(dl=glue_dls['mrpc'][2], with_decoded=True)\n",
    "preds = preds[-1] # preds -> (predictions logits, targets, decoded prediction)\n",
    "cols = ['idx', *textcols(glue_dsets['mrpc']['test'])]\n",
    "test_df = pd.DataFrame( data={**{col:glue_dsets['mrpc']['test'][col] for col in cols}, \n",
    "                             'prediction': preds.tolist()} )\n",
    "test_df.to_csv( test_pred_dir/'MRPC.tsv', sep='\\t' )\n",
    "test_df.head(n=3)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "yKxetBkqfdgm",
    "MqtDnxK9ZYQP",
    "LFcM5MGaafFJ",
    "7cR6NmFsxH10",
    "n1vFihXdx7iQ",
    "pZS8owurxXUV",
    "admPAZ2M2uqO",
    "1NSoV-Np6utL"
   ],
   "name": "Finetune GLUE with fastai.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "007556af2af8413ca47aa5f7f725e68a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2d26c89a3d97493e911c52fa20cf79d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd8da3c0b2784f2094d3b0cfa744cf87",
      "placeholder": "​",
      "style": "IPY_MODEL_5b8f1e5172204ed58bd60972289b24a8",
      "value": " 29.0k/29.0k [00:00&lt;00:00, 39.1kB/s]"
     }
    },
    "5b8f1e5172204ed58bd60972289b24a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "65eee3543a9d46adbc8037995c3a69a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "71beed6de71c4aa2862ef33e21cc58bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8d4771f53c7046f1afe7e04a3a647a31": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9fc29a98d6be46e0974d1f0f7681d5c3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a07124360f4c4249a745891d83e719f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d4771f53c7046f1afe7e04a3a647a31",
      "max": 30329,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_007556af2af8413ca47aa5f7f725e68a",
      "value": 30329
     }
    },
    "a8b32129b9ab41d0895cb1ec445db9ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9fc29a98d6be46e0974d1f0f7681d5c3",
      "max": 28998,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_65eee3543a9d46adbc8037995c3a69a0",
      "value": 28998
     }
    },
    "ae0863b074ff4a1a959514881fe2802f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a8b32129b9ab41d0895cb1ec445db9ca",
       "IPY_MODEL_2d26c89a3d97493e911c52fa20cf79d9"
      ],
      "layout": "IPY_MODEL_e5d5d86746ec4e2298028c57ef775d84"
     }
    },
    "bd8da3c0b2784f2094d3b0cfa744cf87": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1d8bdd9c1a74bc18a103bc900589c2c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5d5d86746ec4e2298028c57ef775d84": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f26a4f6d9334465d9022ab2a3401035b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e1d8bdd9c1a74bc18a103bc900589c2c",
      "placeholder": "​",
      "style": "IPY_MODEL_71beed6de71c4aa2862ef33e21cc58bc",
      "value": " 30.3k/30.3k [00:00&lt;00:00, 392kB/s]"
     }
    },
    "f35afd9d13c240aba4e0619cca0199b7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f74af04bf4764b7888f0a45e37ce85c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a07124360f4c4249a745891d83e719f6",
       "IPY_MODEL_f26a4f6d9334465d9022ab2a3401035b"
      ],
      "layout": "IPY_MODEL_f35afd9d13c240aba4e0619cca0199b7"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
