{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uns2VbU0Yj5f"
   },
   "outputs": [],
   "source": [
    "try: import nlp\n",
    "except ImportError:\n",
    "  % install nlp transformers fastai2\n",
    "  !git clone https://github.com/richardyy1188/Pretrain-MLM-and-finetune-on-GLUE-with-fastai.git\n",
    "  exit() # you may need to restart the kernel to use updated packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "ugFdx5v_YxzA",
    "outputId": "e6663d66-4c4b-4953-8388-7fa2b23b126a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Matplotlib is building the font cache using fc-list. This may take a moment.\n/home/yisiang/Pretrain-MLM-and-finetune-on-GLUE-with-fastai\n"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from IPython.core.debugger import set_trace as bk\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import nlp\n",
    "from transformers import ElectraModel, ElectraConfig, ElectraTokenizer, ElectraTokenizerFast\n",
    "from fastai2.text.all import *\n",
    "%cd Pretrain-MLM-and-finetune-on-GLUE-with-fastai\n",
    "from _utils.would_like_to_pr import *\n",
    "from _utils.hf_integration import *\n",
    "from _utils.multi_task import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6wb0zB6iYyvC"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "40edc66ec482403484b5047bd184eb4e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466.0, style=ProgressStyle(description_…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "838aae0098314ed6b9ff6acc072b1166"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    }
   ],
   "source": [
    "\"\"\" tokenizer and fast tokenizer\n",
    "We use normal tokenizer to get vocab, use fast tokenizer to convert tokens to ids.\n",
    "Because we can't get vocab from fast tokenizer and fast tokenizer is faster,\n",
    "and they share the same token-id mapping.\n",
    "\"\"\"\n",
    "hf_tokenizer = ElectraTokenizer.from_pretrained(\"google/electra-small-discriminator\")\n",
    "hf_fast_tokenizer = ElectraTokenizerFast.from_pretrained(\"google/electra-small-discriminator\")\n",
    "electra_config = ElectraConfig.from_pretrained('google/electra-small-discriminator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yoI6QffPY6Jv"
   },
   "source": [
    "# 1. Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p_P8P4hffUr8"
   },
   "source": [
    "## 1.1 Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W0zfrnOzY9u6"
   },
   "source": [
    "**Download, Preprocess, and Cache**\n",
    "\n",
    "In Colab, it takes you 20+ minutes for the first time, and seconds for subsequent calls. \n",
    "\n",
    "It will cost serveral minutes if you reset runtime even load the cache, but it's not true when you just restart the runtime. So I guess they may keep someth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "ae0863b074ff4a1a959514881fe2802f",
      "e5d5d86746ec4e2298028c57ef775d84",
      "a8b32129b9ab41d0895cb1ec445db9ca",
      "2d26c89a3d97493e911c52fa20cf79d9",
      "65eee3543a9d46adbc8037995c3a69a0",
      "9fc29a98d6be46e0974d1f0f7681d5c3",
      "5b8f1e5172204ed58bd60972289b24a8",
      "bd8da3c0b2784f2094d3b0cfa744cf87",
      "f74af04bf4764b7888f0a45e37ce85c1",
      "f35afd9d13c240aba4e0619cca0199b7",
      "a07124360f4c4249a745891d83e719f6",
      "f26a4f6d9334465d9022ab2a3401035b",
      "007556af2af8413ca47aa5f7f725e68a",
      "8d4771f53c7046f1afe7e04a3a647a31",
      "71beed6de71c4aa2862ef33e21cc58bc",
      "e1d8bdd9c1a74bc18a103bc900589c2c"
     ]
    },
    "colab_type": "code",
    "id": "U-PLcDIRY6y-",
    "outputId": "12e31f13-b70f-48c8-dd45-c6f1718b03c1"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28998.0, style=ProgressStyle(descriptio…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb7106a14a13490a8fba287dfee6efd5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=30329.0, style=ProgressStyle(descriptio…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "09fe3f0ea38b4220899526bd8b425344"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nDownloading and preparing dataset glue/cola (download: 368.14 KiB, generated: 596.73 KiB, total: 964.86 KiB) to /home/yisiang/datasets/glue/cola/1.0.0...\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=376971.0, style=ProgressStyle(descripti…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "32168375c7d34f17ab3ee2427a069208"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1dc9b7c6908e40e383c7671cafe39c42"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2cac1d31f2b346f7b3c6f3313334f92a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f1d52d95cf44c159d0297acc0b62fa9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "0it [00:00, ?it/s]Dataset glue downloaded and prepared to /home/yisiang/datasets/glue/cola/1.0.0. Subsequent calls will reuse this data.\nloading processed datasets of cola ...\n8551it [00:01, 6434.75it/s]\n1043it [00:00, 4681.78it/s]\n1063it [00:00, 4968.69it/s]\nDownloading and preparing dataset glue/sst2 (download: 7.09 MiB, generated: 4.81 MiB, total: 11.90 MiB) to /home/yisiang/datasets/glue/sst2/1.0.0...\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=7439277.0, style=ProgressStyle(descript…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7d330688eab544c3a207ec46dc8a8b7e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "118134e2efb94c47815ff9a4b1d88aa8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ffd5cb5f9a3147608a3c8a21a8be5896"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ccd20b7bfd294f11afca7b53d81e240f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dataset glue downloaded and prepared to /home/yisiang/datasets/glue/sst2/1.0.0. Subsequent calls will reuse this data.\n0it [00:00, ?it/s]loading processed datasets of sst2 ...\n67349it [00:13, 5011.49it/s]\n872it [00:00, 4160.64it/s]\n1821it [00:00, 3565.68it/s]\nDownloading and preparing dataset glue/mrpc (download: 1.43 MiB, generated: 1.43 MiB, total: 2.85 MiB) to /home/yisiang/datasets/glue/mrpc/1.0.0...\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=6222.0, style=ProgressStyle(description…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "65f6d2ac9bad42f3bdf171c93bc686ed"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Downloading', max=1.0, style=ProgressSt…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f6af02fe879b4f3d9ead31a485963747"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Downloading', max=1.0, style=ProgressSt…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be1b6fd39bad454aac0e9ee81b3701e7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "970eb8413dca48ec92a15e084c166197"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "204ace3148f64d5faaf7d66d9855c31d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5068f47aa6ba47a8823bb179d03d9d56"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "0it [00:00, ?it/s]Dataset glue downloaded and prepared to /home/yisiang/datasets/glue/mrpc/1.0.0. Subsequent calls will reuse this data.\nloading processed datasets of mrpc ...\n3668it [00:01, 1989.39it/s]\n408it [00:00, 1979.17it/s]\n1725it [00:00, 2068.52it/s]\nDownloading and preparing dataset glue/qqp (download: 57.73 MiB, generated: 107.02 MiB, total: 164.75 MiB) to /home/yisiang/datasets/glue/qqp/1.0.0...\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=60534884.0, style=ProgressStyle(descrip…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7fb5d4ff9cc44a8d9837f5150295202b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dc1a7864c3b040198dea58d4671e88f7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5424b89068d14b49a56dfb874f2c2076"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "08e85b73ed094b5e96013475ce53dfcc"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dataset glue downloaded and prepared to /home/yisiang/datasets/glue/qqp/1.0.0. Subsequent calls will reuse this data.\n256it [00:00, 2555.00it/s]loading processed datasets of qqp ...\n363849it [02:11, 2766.69it/s]\n40430it [00:14, 2847.80it/s]\n390965it [02:01, 3223.29it/s]\nDownloading and preparing dataset glue/stsb (download: 784.05 KiB, generated: 1.09 MiB, total: 1.86 MiB) to /home/yisiang/datasets/glue/stsb/1.0.0...\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=802872.0, style=ProgressStyle(descripti…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8ccee36349574571a05c3bfbc1cde127"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "00fc5b5b6e9144249dcce4e8d47b3de8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6235ac7a3d254cd39f7d8c3dceb7b93b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e55f1a5c01c4122b49c38215f4f6e72"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "0it [00:00, ?it/s]Dataset glue downloaded and prepared to /home/yisiang/datasets/glue/stsb/1.0.0. Subsequent calls will reuse this data.\nloading processed datasets of stsb ...\n5749it [00:02, 2730.93it/s]\n1500it [00:00, 3398.48it/s]\n1379it [00:00, 2801.81it/s]\nDownloading and preparing dataset glue/mnli (download: 298.29 MiB, generated: 78.65 MiB, total: 376.95 MiB) to /home/yisiang/datasets/glue/mnli/1.0.0...\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=312783507.0, style=ProgressStyle(descri…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a69e13e15c754caebe7f06043d5053ac"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "491558f9ca9141179ec6bdc95e938ca4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bbfe611e7afc4f8797146659779dbe0e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c49931e8fdbf4b4faa2450261f8a758c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8eb8cbf0d9f4be5b80eeaef0ce2ea8d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da4ab791557c4c649906bf548d1db1b9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dataset glue downloaded and prepared to /home/yisiang/datasets/glue/mnli/1.0.0. Subsequent calls will reuse this data.\n207it [00:00, 2046.02it/s]loading processed datasets of mnli ...\n392702it [02:22, 2763.50it/s]\n9815it [00:03, 2468.20it/s]\n9832it [00:03, 2596.52it/s]\n9796it [00:03, 2585.49it/s]\n9847it [00:03, 2726.11it/s]\nDownloading and preparing dataset glue/qnli (download: 10.14 MiB, generated: 27.11 MiB, total: 37.24 MiB) to /home/yisiang/datasets/glue/qnli/1.0.0...\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=10627589.0, style=ProgressStyle(descrip…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "56d78cc83bd740d980340b1a9eb952d3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b27457682b7f449585fc8fc595a20ef0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ced2cede46945f8a6c4595f1f5b1e23"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f17c91f138ad4254b8b724453fa89877"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dataset glue downloaded and prepared to /home/yisiang/datasets/glue/qnli/1.0.0. Subsequent calls will reuse this data.\n194it [00:00, 1938.05it/s]loading processed datasets of qnli ...\n104743it [00:39, 2671.79it/s]\n5463it [00:02, 2015.96it/s]\n5463it [00:02, 2199.20it/s]\nDownloading and preparing dataset glue/rte (download: 680.81 KiB, generated: 1.83 MiB, total: 2.49 MiB) to /home/yisiang/datasets/glue/rte/1.0.0...\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=697150.0, style=ProgressStyle(descripti…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "418135b7d8b94be4acf61704097e092f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eafc74fca7fb47b2b594125d9db08a39"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b4be80b017b49d5853f7b545820dc64"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e6ab5e512657466f8c8543fcb790596d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dataset glue downloaded and prepared to /home/yisiang/datasets/glue/rte/1.0.0. Subsequent calls will reuse this data.\n181it [00:00, 1803.11it/s]loading processed datasets of rte ...\n2490it [00:01, 1767.64it/s]\n277it [00:00, 1776.69it/s]\n3000it [00:01, 1871.79it/s]\nDownloading and preparing dataset glue/wnli (download: 28.32 KiB, generated: 154.03 KiB, total: 182.35 KiB) to /home/yisiang/datasets/glue/wnli/1.0.0...\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28999.0, style=ProgressStyle(descriptio…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "247efc5c719b4b438dd91fbdc7892031"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7fb845c5d7634b5787ed6a0ca3364779"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dea4a77234f848dcb669c86b4137ff84"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f93d09831879468fb03850cfb49d5573"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "240it [00:00, 2399.21it/s]Dataset glue downloaded and prepared to /home/yisiang/datasets/glue/wnli/1.0.0. Subsequent calls will reuse this data.\nloading processed datasets of wnli ...\n635it [00:00, 2297.31it/s]\n71it [00:00, 2015.62it/s]\n146it [00:00, 1927.43it/s]\nDownloading and preparing dataset glue/ax (download: 217.05 KiB, generated: 232.80 KiB, total: 449.85 KiB) to /home/yisiang/datasets/glue/ax/1.0.0...\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=222257.0, style=ProgressStyle(descripti…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "759370fdb87b48868267ead4d0ce336c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c198b7fb71dc43278357ad5b9fa48e03"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "0it [00:00, ?it/s]Dataset glue downloaded and prepared to /home/yisiang/datasets/glue/ax/1.0.0. Subsequent calls will reuse this data.\nloading processed datasets of ax ...\n1104it [00:00, 2238.39it/s]\n"
    }
   ],
   "source": [
    "# create a 'glue' folder under it, and all cache files will be under 'glue'\n",
    "cache_dir=Path('~/datasets')\n",
    "cache_dir.mkdir(parents=True, exist_ok=True) # create recursively if not exist\n",
    "\n",
    "def textcols(dataset):\n",
    "  \"Infer text cols of different GLUE datasets in huggingface/nlp\"\n",
    "  column_names = dataset.column_names\n",
    "  if 'question' in column_names: return ['question', 'sentence']\n",
    "  elif 'sentence1' in column_names: return ['sentence1', 'sentence2']\n",
    "  elif 'question1' in column_names: return ['question1','question2']\n",
    "  elif 'premise' in column_names: return ['premise','hypothesis']\n",
    "  elif 'sentence' in column_names: return ['sentence']\n",
    "\n",
    "\"\"\"\n",
    "quote from transformers tutorial of fastai (http://dev.fast.ai/tutorial.transformers)\n",
    "we don't use the tokenizer.encode method since it does some additional preprocessing for the model after tokenizing and numericalizing (the aprt throwing a warning before). Here we don't need any post-processing so it's fine to skip it.\n",
    "\"\"\"\n",
    "def tokenize_sents(example, cols):\n",
    "  if len(cols)==1:\n",
    "    example['input_ids'] = hf_fast_tokenizer.convert_tokens_to_ids(hf_fast_tokenizer.tokenize(f\"[CLS] {example[cols[0]]} [SEP]\"))\n",
    "  elif len(cols)==2:\n",
    "    example['input_ids'] = concat(hf_fast_tokenizer.convert_tokens_to_ids(hf_fast_tokenizer.tokenize(f'[CLS] {example[cols[0]]} [SEP]')),\n",
    "                                  hf_fast_tokenizer.convert_tokens_to_ids(hf_fast_tokenizer.tokenize(f'{example[cols[1]]} [SEP]')))\n",
    "  else: raise ValueError()\n",
    "  return example\n",
    "\n",
    "glue_dsets = {}\n",
    "for glue_task in ['cola', 'sst2', 'mrpc', 'qqp', 'stsb', 'mnli', 'qnli', 'rte', 'wnli', 'ax']:\n",
    "  task = nlp.load_dataset('glue', glue_task, cache_dir=cache_dir)\n",
    "  glue_dsets[glue_task] = {}\n",
    "  print(f'loading processed datasets of {glue_task} ...')\n",
    "  for split in task.keys():\n",
    "    raw_dataset = task[split]\n",
    "    cache_file = Path(raw_dataset.cache_files[0]['filename']).parent / f'tokenized_{split}.arrow'\n",
    "    if cache_file.exists():dataset = nlp.Dataset.from_file(str(cache_file))\n",
    "    else: dataset = raw_dataset.map(partial(tokenize_sents, cols=textcols(raw_dataset)),\n",
    "                                    cache_file_name=str(cache_file))\n",
    "    glue_dsets[glue_task][split] = dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yKxetBkqfdgm"
   },
   "source": [
    "## 1.2 hf/hlp datasets -> fastai dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Oc3ZjYwZGLn"
   },
   "outputs": [],
   "source": [
    "# I don't know how to let `Learner` validate two validation sets every epochs, so I just merged `mnli validation mismatched` and `mnli validation matched`.\n",
    "glue_dsets['mnli']['validation'] = HF_MergedDataset(glue_dsets['mnli']['validation_matched'], glue_dsets['mnli']['validation_mismatched'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R4mAI-scZSQh"
   },
   "outputs": [],
   "source": [
    "def text_decode_fc(x, pretty=True):\n",
    "  if pretty:\n",
    "    return hf_fast_tokenizer.decode([idx for idx in x if idx != hf_fast_tokenizer.pad_token_id])\n",
    "  else:\n",
    "    tokens = hf_fast_tokenizer.convert_ids_to_tokens(x)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "@delegates(FilteredBase.dataloaders)\n",
    "def get_glue_dls(task_name, **kwargs):\n",
    "  assert task_name in ['cola', 'sst2', 'mrpc', 'qqp', 'stsb', 'mnli', 'qnli', 'rte', 'wnli', 'ax']\n",
    "  splits = ['train','validation']+(['test'] if task_name != 'mnli' else ['test_matched', 'test_mismatched'])\n",
    "  if task_name == 'ax': splits = ['test']\n",
    "  arrow_dsets = [glue_dsets[task_name][s] for s in splits ]\n",
    "  show_pretty = kwargs.pop('show_pretty', True) \n",
    "  dsets = HF_Datasets(datasets=arrow_dsets, \n",
    "                      cols=['input_ids', 'label'],\n",
    "                      encode_types=[TensorText, noop],\n",
    "                      decode_funcs=[partial(text_decode_fc,pretty=show_pretty),noop],\n",
    "                      decode_types=[TitledStr, lambda x: Category(x.item())])\n",
    "  dl_cache_files = [Path(dset.cache_files[0]['filename']).parent/f'dl_{s}.pth' for dset, s in zip(dsets,splits)]\n",
    "  if all([ p.exists() for p in dl_cache_files]):\n",
    "    device = kwargs.pop('device', default_device())\n",
    "    dl_s = [TextDataloader.from_cache(f, dsets[i], bs=32, **kwargs) for i, f in enumerate(dl_cache_files)]  \n",
    "    dls = DataLoaders(*dl_s, device=device)\n",
    "  else:\n",
    "    dls = dsets.dataloaders(before_batch=partial(pad_input_chunk,pad_first=False,pad_idx=hf_fast_tokenizer.pad_token_id,),\n",
    "                             dl_type=partial(TextDataloader, sort_by_len=False),\n",
    "                            bs=32,\n",
    "                             **kwargs)\n",
    "    for dl, cache_f in zip(dls,dl_cache_files): dl.cache(cache_f)\n",
    "  return dls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MqtDnxK9ZYQP"
   },
   "source": [
    "## 1.3 Get dataloaders fror each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0VYQubDaZbRv"
   },
   "source": [
    "**[CoLA](https://nyu-mll.github.io/CoLA/)** (*The Corpus of Linguistic Acceptability*):\n",
    "\n",
    "\n",
    "Check whether a sentence is linguistically acceptable. \n",
    "\n",
    "(0: unacceptable, 1: acceptable) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "HhZ3HD7VZalK",
    "outputId": "7ea5edbf-6a70-4f5a-9b85-c033e7aef666"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "TextDataloader init::  74%|███████▍  | 787/1063 [00:00<00:00, 7862.02it/s]Dataset size (train/valid/test): 8551/1043/1063\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[CLS] our friends won't buy this analysis, let alone the next one we propose. [SEP]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[CLS] one more pseudo generalization and i'm giving up. [SEP]</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "cola_dls = get_glue_dls('cola', show_bar=False)\n",
    "print(f\"Dataset size (train/valid/test): {len(cola_dls[0].dataset)}/{len(cola_dls[1].dataset)}/{len(cola_dls[2].dataset)}\")\n",
    "cola_dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ZJ2zGxJZiyq"
   },
   "source": [
    "**Note**: for the readibility, we won't show pad and result of sentencepiece ('##...') here, which are the actual results in a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "j1zl6tm6Zk02",
    "outputId": "e6212d7a-b03b-41c4-ac46-e8a7633ad4be"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[CLS] our friends won ' t buy this analysis , let alone the next one we propose . [SEP]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[CLS] one more pseudo general ##ization and i ' m giving up . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "get_glue_dls('cola', show_bar=False, show_pretty=False).show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "STiSJYdbZns1"
   },
   "source": [
    "**[SST-2](https://nlp.stanford.edu/sentiment/index.html)** (*The Stanford Sentiment Treebank*): \n",
    "\n",
    "Identify the sentiment of a work/phrase/sentence. \n",
    "\n",
    "(1: positvie, 0: negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "ouo5jT9sZnKG",
    "outputId": "ef107490-d6b8-4551-9028-33cc299fc674"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "TextDataloader init::  94%|█████████▍| 1715/1821 [00:00<00:00, 8608.88it/s]Dataset size (train/valid/test): 67349/872/1821\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[CLS] hide new secretions from the parental units [SEP]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[CLS] contains no wit, only labored gags [SEP]</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "sst2_dls = get_glue_dls('sst2')\n",
    "print(f\"Dataset size (train/valid/test): {len(sst2_dls[0].dataset)}/{len(sst2_dls[1].dataset)}/{len(sst2_dls[2].dataset)}\")\n",
    "sst2_dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wecP4wm0ZqfX"
   },
   "source": [
    "**[MRPC](https://www.microsoft.com/en-us/download/details.aspx?id=52398)** (*Microsoft Research Paraphrase Corpus*): \n",
    "\n",
    "Whether each pair captures a paraphrase/semantic equivalence relationship. \n",
    "\n",
    "(1: yes, 0: no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "6T54EE4WZxgW",
    "outputId": "98e94bdb-324d-4d80-b367-7f4f6da2efb1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "TextDataloader init::  94%|█████████▍| 1625/1725 [00:00<00:00, 5307.00it/s]Dataset size (train/valid/test): 67349/872/57\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[CLS] amrozi accused his brother, whom he called \" the witness \", of deliberately distorting his evidence. [SEP] referring to him as only \" the witness \", amrozi accused his brother of deliberately distorting his evidence. [SEP]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[CLS] yucaipa owned dominick's before selling the chain to safeway in 1998 for $ 2. 5 billion. [SEP] yucaipa bought dominick's in 1995 for $ 693 million and sold it to safeway for $ 1. 8 billion in 1998. [SEP]</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "mrpc_dls = get_glue_dls('mrpc',show_bar=False)\n",
    "print(f\"Dataset size (train/valid/test): {len(sst2_dls.train_ds)}/{len(sst2_dls.valid_ds)}/{len(sst2_dls[2])}\")\n",
    "mrpc_dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "znmNswfyZuCb"
   },
   "source": [
    "**[STS-B](http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark)** (*Semantic Textual Similarity Benchmark*):\n",
    "\n",
    "Score the similarity of meanings of two sentences. The only regression task in GLUE \n",
    "\n",
    "(0.0 ~ 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "631vsrFwaDHB",
    "outputId": "380a5db6-b00b-49aa-a5d7-7d4cedba576e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "TextDataloader init::  54%|█████▍    | 748/1379 [00:00<00:00, 7475.41it/s]Dataset size (train/valid/test): 5749/1500/44\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[CLS] a plane is taking off. [SEP] an air plane is taking off. [SEP]</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[CLS] a man is playing a large flute. [SEP] a man is playing a flute. [SEP]</td>\n      <td>3.799999952316284</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "stsb_dls = get_glue_dls('stsb',show_bar=False)\n",
    "print(f\"Dataset size (train/valid/test): {len(stsb_dls.train_ds)}/{len(stsb_dls.valid_ds)}/{len(stsb_dls[2])}\")\n",
    "stsb_dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YR_ok10uaCYM"
   },
   "source": [
    "**[QQP](https://www.quora.com/q/quoradata/First-Quora-Dataset-Release-Question-Pairs)** (*Quora Question Pairs*)\n",
    "\n",
    "Check whether two questions are duplicated. \n",
    "\n",
    "(0: no, 1: duplicated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "hWQc8402aFJb",
    "outputId": "8a4e6617-47e4-4a92-bc56-481730a16088"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "TextDataloader init:: 100%|█████████▉| 390458/390965 [01:07<00:00, 5093.99it/s]Dataset size (train/valid/test): 363849/40430/12218\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[CLS] how is the life of a math student? could you describe your own experiences? [SEP] which level of prepration is enough for the exam jlpt5? [SEP]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[CLS] how do i control my horny emotions? [SEP] how do you control your horniness? [SEP]</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "qqp_dls = get_glue_dls('qqp')\n",
    "print(f\"Dataset size (train/valid/test): {len(qqp_dls.train_ds)}/{len(qqp_dls.valid_ds)}/{len(qqp_dls[2])}\")\n",
    "qqp_dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dnZm1zqEaHHB"
   },
   "source": [
    "**[MNLI](https://cims.nyu.edu/~sbowman/multinli/)** (*The Multi-Genre NLI Corpus*)\n",
    "\n",
    "Whether the premise (sentence 1) entails the hypothesis (sentence 2) (entailment), contradicts the hypothesis (contradiction), or neither (neutral) \n",
    "\n",
    "(0: entailment, 1: neutral, 2: contradiction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "3PRuXBJ8aJTH",
    "outputId": "89fd1479-796c-43ef-ee71-292ac6ed4bad"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "TextDataloader init::  97%|█████████▋| 9600/9847 [00:01<00:00, 5866.34it/s]Dataset size (train/valid/test_matched/test_mismatched): 392702/19647/9796/9847\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[CLS] conceptually cream skimming has two basic dimensions - product and geography. [SEP] product and geography are what make cream skimming work. [SEP]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[CLS] you know during the season and i guess at at your level uh you lose them to the next level if if they decide to recall the the parent team the braves decide to call to recall a guy from triple a then a double a guy goes up to replace him and a single a guy goes up to replace him [SEP] you lose the things to the following level if the people recall. [SEP]</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "mnli_dls = get_glue_dls('mnli')\n",
    "print(f\"Dataset size (train/valid/test_matched/test_mismatched): {len(mnli_dls[0].dataset)}/{len(mnli_dls[1].dataset)}/{len(mnli_dls[2].dataset)}/{len(mnli_dls[3].dataset)}\")\n",
    "mnli_dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PJKg-BSkaPN5"
   },
   "source": [
    "**QNLI** (*The Stanford Question Answering Dataset*):\n",
    "\n",
    "The task is to determine whether the context sentence (sentence 2) contains the answer to the question (sentence 1).\n",
    "\n",
    "(0: entailment, 1: not_entailment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "DIK9BAnBaLbj",
    "outputId": "62ee8573-b4f6-4274-9592-44920c010674"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "TextDataloader init::  87%|████████▋ | 4744/5463 [00:00<00:00, 7890.57it/s]Dataset size (train/valid/test): 104743/5463/5463\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[CLS] when did the third digimon series begin? [SEP] unlike the two seasons before it and most of the seasons that followed, digimon tamers takes a darker and more realistic approach to its story featuring digimon who don't reincarnate after their deaths and more complex character development in the original japanese. [SEP]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[CLS] which missile batteries often have individual launchers several kilometres from one another? [SEP] when manpads is operated by specialists, batteries may have several dozen teams deploying separately in small sections ; self - propelled air defence guns may deploy in pairs. [SEP]</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "qnli_dls = get_glue_dls('qnli')\n",
    "print(f\"Dataset size (train/valid/test): {len(qnli_dls[0].dataset)}/{len(qnli_dls[1].dataset)}/{len(qnli_dls[2].dataset)}\")\n",
    "qnli_dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I2OPdiDpaS6v"
   },
   "source": [
    "**[RTE](https://aclweb.org/aclwiki/Recognizing_Textual_Entailment)** (*Recognizing_Textual_Entailment*):\n",
    "\n",
    "Whether hypothesis (sentence 2) is entailed (can be inferred) from the premise (sentence 1).\n",
    "\n",
    "(0: entailment, 1: not_entailment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "cODdx4WyaVRh",
    "outputId": "ee44b782-8da0-42a8-ef6f-b17a841679df"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "TextDataloader init::  92%|█████████▏| 2773/3000 [00:00<00:00, 5403.06it/s]Dataset size (train/valid/test): 2490/277/3000\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[CLS] no weapons of mass destruction found in iraq yet. [SEP] weapons of mass destruction found in iraq. [SEP]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[CLS] a place of sorrow, after pope john paul ii died, became a place of celebration, as roman catholic faithful gathered in downtown chicago to mark the installation of new pope benedict xvi. [SEP] pope benedict xvi is the new leader of the roman catholic church. [SEP]</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "rte_dls = get_glue_dls('rte', show_bar=False)\n",
    "print(f\"Dataset size (train/valid/test): {len(rte_dls[0].dataset)}/{len(rte_dls[1].dataset)}/{len(rte_dls[2].dataset)}\")\n",
    "rte_dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E-iIX2EaaUt-"
   },
   "source": [
    "**[WNLI](https://cs.nyu.edu/faculty/davise/papers/WinogradSchemas/WS.html)** (*The Winograd Schema Challenge*)\n",
    "\n",
    "Check whether sentence 2 (which is rephrased sentence of sentence 1) correctly solve the pronoun in sentence 1.\n",
    "\n",
    "(0: wrong, 1: correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "L7wGvrihaZAj",
    "outputId": "df1fad6b-d779-4fe9-f9c8-53bacf5eec07"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "TextDataloader init::   0%|          | 0/146 [00:00<?, ?it/s]Dataset size (train/valid/test): 635/71/146\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[CLS] i stuck a pin through a carrot. when i pulled the pin out, it had a hole. [SEP] the carrot had a hole. [SEP]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[CLS] john couldn't see the stage with billy in front of him because he is so short. [SEP] john is so short. [SEP]</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "wnli_dls = get_glue_dls('wnli', show_bar=False)\n",
    "print(f\"Dataset size (train/valid/test): {len(wnli_dls[0].dataset)}/{len(wnli_dls[1].dataset)}/{len(wnli_dls[2].dataset)}\")\n",
    "wnli_dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0RQ-BEaIaa8F"
   },
   "source": [
    "**[AX](https://gluebenchmark.com/diagnostics)** (*GLUE Diagnostic Dataset*):\n",
    "\n",
    "Whether the premise (sentence 1) entails the hypothesis (sentence 2) (entailment), contradicts the hypothesis (contradiction), or neither (neutral) \n",
    "\n",
    "Test set only.\n",
    "\n",
    "The label is all -1, because this is a test dataset and the answers is kept by GLUE benchmark and not provided. The categories are the same as MNLI (entailment, neutral, contradiction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "5IKH0iJKadAW",
    "outputId": "0c5935c4-608f-426e-f3d0-9d380df14fa8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "TextDataloader init::  53%|█████▎    | 584/1104 [00:00<00:00, 5833.69it/s]Dataset size (test): 1104\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[CLS] the cat sat on the mat. [SEP] the cat did not sit on the mat. [SEP]</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[CLS] the cat did not sit on the mat. [SEP] the cat sat on the mat. [SEP]</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "ax_dls = get_glue_dls('ax')\n",
    "print(f\"Dataset size (test): {len(ax_dls[0].dataset)}\")\n",
    "ax_dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3wRQS_H1aekI"
   },
   "outputs": [],
   "source": [
    "glue_dls = {}\n",
    "for task_name in ['cola', 'sst2', 'mrpc', 'qqp', 'stsb', 'mnli', 'qnli', 'rte', 'wnli', 'ax']:\n",
    "  dls = eval(f\"{task_name}_dls\")\n",
    "  if task_name != 'ax':\n",
    "    dls[0].desc_sort(); dls[1].desc_sort(); # sort by len to reduce pad, but not for test_dl which keep the order of sample to let us add the dataset idx conveniently later \n",
    "  glue_dls[task_name] = dls\n",
    "glue_dls['ax'][0].shuffle = False # fastai see 0th dl as train_dl which is default shuffled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LFcM5MGaafFJ"
   },
   "source": [
    "# 2. Finetuning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tUGxkcDfQGxS"
   },
   "source": [
    "* ELECTRA use CLS encodings as pooled result to predict the sentence. (see [here](https://github.com/google-research/electra/blob/79111328070e491b287c307906701ebc61091eb2/model/modeling.py#L254) of its official repository)\n",
    "\n",
    "* Note that we should use different prediction head for different tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MF6vajgKQKJ7"
   },
   "outputs": [],
   "source": [
    "class SentencePredictHead(nn.Module):\n",
    "  \"The way that Electra and Bert do for sentence prediction task\"\n",
    "  def __init__(self, hidden_size, targ_voc_size):\n",
    "    super().__init__()\n",
    "    self.linear = nn.Linear(hidden_size, targ_voc_size)\n",
    "    self.dropout = nn.Dropout(0.1)\n",
    "  def forward(self, x):\n",
    "    \"x: (batch size, sequence length, hidden_size)\"\n",
    "    return self.linear(self.dropout(x[:,0])) # project the first token (a special token)'s hidden encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hRoFPXjpe4Nb"
   },
   "source": [
    "`SentencePredictHead`\n",
    "* change `targ_voc_size` for diffrent task\n",
    "* change `256` for your model's hidden size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "K3_2P-uZV8sb",
    "outputId": "f114b91b-c088-4192-a193-128ede97721b"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=54245363.0, style=ProgressStyle(descrip…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "616079ae88674ea6868f056d5c8f72f4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\ninput shape: torch.Size([1, 13]) (batch size, sequence length)\noutput shape: torch.Size([1, 2]) (batch_size, target vocab size)\nThe output is the raw score-like thing for each label\ntensor([[-0.3773, -0.7221]])\n"
    }
   ],
   "source": [
    "single_task_model = nn.Sequential(HF_ModelWrapper.from_pretrained(ElectraModel, 'google/electra-small-discriminator', pad_id=hf_tokenizer.pad_token_id, sep_id=hf_tokenizer.sep_token_id), # specify spe_id and wrapper will create and pass token_type_ids of sentece A/B for you\n",
    "                                  SentencePredictHead(electra_config.hidden_size, targ_voc_size=2)) \n",
    "inp_tensor = torch.tensor(hf_tokenizer.encode('I am the sentence A','I am the sentence B'))[None,:] \n",
    "print(f'input shape: {inp_tensor.shape} (batch size, sequence length)')\n",
    "with torch.no_grad(): out_tensor = single_task_model(inp_tensor)\n",
    "print(f'output shape: {out_tensor.shape} (batch_size, target vocab size)')\n",
    "print(f'The output is the raw score-like thing for each label')\n",
    "print(out_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zi5_OKHqX8qw"
   },
   "source": [
    "# 3. Single Task Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "poNJYRwETtBo"
   },
   "source": [
    "## 3.1 Discriminative learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7OyT-hy-7FXz"
   },
   "outputs": [],
   "source": [
    "# Names come from, for nm in model.named_modules(): print(nm[0])\n",
    "def hf_electra_param_splitter(model, num_hidden_layers, outlayer_name):\n",
    "  names = ['model.embeddings', *[f'model.encoder.layer.{i}' for i in range(num_hidden_layers)], outlayer_name]\n",
    "  def endswith_any(n,ns): return any([ n.endswith(suffix) for suffix in ns])\n",
    "  groups = [ list(mod.parameters()) for name, mod in model.named_modules() if endswith_any(name, names) ]\n",
    "  assert len(groups) == len(names)\n",
    "  return groups\n",
    "\n",
    "def get_layer_lrs(lr, decay_rate_of_depth, num_hidden_layers):\n",
    "  # I think input layer as bottom and output layer as top, which make 'depth' mean different from the one of official repo \n",
    "  return [ lr * (decay_rate_of_depth ** depth) for depth in reversed(range(num_hidden_layers+2))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N2ug-bscA9gC"
   },
   "source": [
    "## 3.2 Learning rate schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nzqFhWQkBGhu"
   },
   "outputs": [],
   "source": [
    "def linear_warmup_and_decay(pct_now, lr_max, end_lr, decay_power, warmup_pct, total_steps):\n",
    "  \"\"\"\n",
    "  end_lr: the end learning rate for linear decay\n",
    "  warmup_pct: percentage of training steps to for linear increase\n",
    "  pct_now: percentage of traning steps we have gone through, notice pct_now=0.0 when calculating lr for first batch.\n",
    "  \"\"\"\n",
    "  \"\"\"\n",
    "  pct updated after_batch, but global_step (in tf) seems to update before optimizer step,\n",
    "  so pct is actually (global_step -1)/total_steps \n",
    "  \"\"\"\n",
    "  fixed_pct_now = pct_now + 1/total_steps\n",
    "  \"\"\"\n",
    "  According to source code of the official repository, it seems they merged two lr schedule (warmup and linear decay)\n",
    "  sequentially, instead of split training into two phases for each, this might because they think when in the early\n",
    "  phase of training, pct is low, and thus the decaying formula makes little difference to lr.\n",
    "  \"\"\"\n",
    "  decayed_lr = (lr_max-end_lr) * (1-fixed_pct_now)**decay_power + end_lr # https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/polynomial_decay\n",
    "  warmed_lr = decayed_lr * min(1.0, fixed_pct_now / warmup_pct) # https://github.com/google-research/electra/blob/81f7e5fc98b0ad8bfd20b641aa8bc9e6ac00c8eb/model/optimization.py#L44\n",
    "  return warmed_lr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Mcjq0b8wbkO"
   },
   "source": [
    "## 3.3 finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = {\n",
    "  **{ task:['MatthewsCorrCoef'] for task in ['cola']},\n",
    "  **{ task:['Accuracy'] for task in ['sst2', 'mnli', 'qnli', 'rte', 'wnli', 'snli']},\n",
    "  # Note: MRPC and QQP are both binary classification problem, so we can just use fastai's default\n",
    "  # average option 'binary' without spcification of average method.\n",
    "  **{ task:['F1Score', 'Accuracy'] for task in ['mrpc', 'qqp']}, \n",
    "  **{ task:['PearsonCorrCoef', 'SpearmanCorrCoef'] for task in ['stsb']}\n",
    "}\n",
    "TARG_VOC_SIZE = {\n",
    "    **{ task:1 for task in ['stsb']},\n",
    "    **{ task:2 for task in ['cola', 'sst2', 'mrpc', 'qqp', 'qnli', 'rte', 'wnli']},\n",
    "    **{ task:3 for task in ['mnli','ax']}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Table 7 of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glue_learner(electra_config, task, use_one_cycle=False, fp16=False):\n",
    "    if electra_config.hidden_size == 256: learing_rate = 3e-4; lr_depth_decay=0.8\n",
    "    elif electra_config.hidden_size == 768: learing_rate = 1e-4; lr_depth_decay=0.8\n",
    "    elif electra_config.hidden_size == 1024: learing_rate = 5e-5; lr_depth_decay=0.9\n",
    "    if task == 'rte': num_epoch = 10\n",
    "    else: num_epochs = 3\n",
    "    \n",
    "    model = nn.Sequential(HF_ModelWrapper.from_pretrained(ElectraModel, 'google/electra-small-discriminator', pad_id=hf_tokenizer.pad_token_id, sep_id=hf_tokenizer.sep_token_id), # specify spe_id and wrapper will create and pass token_type_ids of sentece A/B for you\n",
    "                                    SentencePredictHead(electra_config.hidden_size, targ_voc_size=TARG_VOC_SIZE[task]))\n",
    "    dls = glue_dls[task]\n",
    "    layer_lrs = get_layer_lrs(lr=learing_rate,\n",
    "                            decay_rate_of_depth=lr_depth_decay,\n",
    "                            num_hidden_layers=electra_config.num_hidden_layers)\n",
    "    lr_shedule = ParamScheduler({'lr': partial(linear_warmup_and_decay,\n",
    "                                            lr_max=np.array(layer_lrs),\n",
    "                                            end_lr=0.0,\n",
    "                                            decay_power=1,\n",
    "                                            warmup_pct=0.1,\n",
    "                                            total_steps=num_epochs*(len(dls.train)))})\n",
    "    learn = Learner(dls, single_task_model,\n",
    "                    loss_func=CrossEntropyLossFlat() if task != 'stsb' else MSELossFlat(), \n",
    "                    opt_func=partial(Adam, eps=1e-6,),\n",
    "                    metrics=[eval(f'{metric}()') for metric in METRICS[task]],\n",
    "                    splitter=partial(hf_electra_param_splitter, \n",
    "                                    num_hidden_layers=electra_config.num_hidden_layers, \n",
    "                                    outlayer_name='1'),\n",
    "                    lr=layer_lrs if use_one_cycle else defaults.lr,)\n",
    "    if fp16: learn = learn.fp16()\n",
    "    return learn, num_epochs, None if use_one_cycle else lr_shedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "iy6g3alOACMv",
    "outputId": "11aa5215-4f54-485e-85d6-35eb8233458c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(#6) [0,0.16408467292785645,0.4083312153816223,0.8850174216027874,0.8382353186607361,'00:10']\n(#6) [1,0.07920170575380325,0.6186863780021667,0.8796992481203008,0.843137264251709,'00:11']\n(#6) [2,0.047114238142967224,0.6189014315605164,0.8900900900900901,0.8504902124404907,'00:10']\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 413.589876 248.518125\" width=\"413.589876pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 248.518125 \nL 413.589876 248.518125 \nL 413.589876 0 \nL -0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 69.23125 224.64 \nL 404.03125 224.64 \nL 404.03125 7.2 \nL 69.23125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"md069e2625c\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"84.449432\" xlink:href=\"#md069e2625c\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(81.268182 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"129.077531\" xlink:href=\"#md069e2625c\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 50 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(122.715031 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"173.70563\" xlink:href=\"#md069e2625c\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 100 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(164.16188 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"218.333729\" xlink:href=\"#md069e2625c\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 150 -->\n      <g transform=\"translate(208.789979 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"262.961829\" xlink:href=\"#md069e2625c\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 200 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(253.418079 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"307.589928\" xlink:href=\"#md069e2625c\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 250 -->\n      <g transform=\"translate(298.046178 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"352.218027\" xlink:href=\"#md069e2625c\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 300 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(342.674277 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"396.846126\" xlink:href=\"#md069e2625c\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 350 -->\n      <g transform=\"translate(387.302376 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mf92800995a\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.23125\" xlink:href=\"#mf92800995a\" y=\"214.756364\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.00000 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(20.878125 218.555582)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"349.902344\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.23125\" xlink:href=\"#mf92800995a\" y=\"178.054913\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.00005 -->\n      <g transform=\"translate(20.878125 181.854131)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"349.902344\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.23125\" xlink:href=\"#mf92800995a\" y=\"141.353462\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.00010 -->\n      <g transform=\"translate(20.878125 145.15268)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"349.902344\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.23125\" xlink:href=\"#mf92800995a\" y=\"104.652011\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.00015 -->\n      <g transform=\"translate(20.878125 108.451229)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"349.902344\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.23125\" xlink:href=\"#mf92800995a\" y=\"67.95056\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.00020 -->\n      <g transform=\"translate(20.878125 71.749778)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"349.902344\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.23125\" xlink:href=\"#mf92800995a\" y=\"31.249109\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.00025 -->\n      <g transform=\"translate(20.878125 35.048327)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"349.902344\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_15\">\n     <!-- lr -->\n     <defs>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n      <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n     </defs>\n     <g transform=\"translate(14.798437 119.364531)rotate(-90)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-114\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#p710c2cf62e)\" d=\"M 84.449432 208.33634 \nL 90.697366 164.450486 \nL 96.052738 128.302551 \nL 101.40811 93.510163 \nL 106.763481 60.073322 \nL 112.118853 27.992029 \nL 113.903977 17.599498 \nL 114.796539 17.083636 \nL 388.813068 214.756364 \nL 388.813068 214.756364 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 69.23125 224.64 \nL 69.23125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 404.03125 224.64 \nL 404.03125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 69.23125 224.64 \nL 404.03125 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 69.23125 7.2 \nL 404.03125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p710c2cf62e\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"69.23125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "single_task_learn, num_epochs, shed = get_glue_learner(electra_config, 'mrpc',)\n",
    "with single_task_learn.no_bar():\n",
    "    if shed is not None: single_task_learn.fit(n_epoch=num_epochs, cbs=[shed])\n",
    "    else: single_task_learn.fit(n_epoch=num_epochs)\n",
    "single_task_learn.recorder.plot_sched() # print last lr of last paramters groups (output layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c73X4fdrmnlP"
   },
   "source": [
    "## 3.3 Predict the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EYMsFM0Cmp1k"
   },
   "outputs": [],
   "source": [
    "test_pred_dir = cache_dir/'glue'/'test'\n",
    "test_pred_dir.mkdir(exist_ok=True)\n",
    "preds = single_task_learn.get_preds(dl=glue_dls['mrpc'][2], with_decoded=True)\n",
    "preds = preds[-1] # preds -> (predictions logits, targets, decoded prediction)\n",
    "cols = ['idx', *textcols(glue_dsets['mrpc']['test'])]\n",
    "test_df = pd.DataFrame( data={**{col:glue_dsets['mrpc']['test'][col] for col in cols}, \n",
    "                             'prediction': preds.tolist()} )\n",
    "test_df.to_csv( test_pred_dir/'MRPC.tsv', sep='\\t' )\n",
    "test_df.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Multi-task learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tasks = ['cola', 'sst2', 'mrpc', 'qqp', 'stsb', 'mnli', 'qnli', 'rte', 'wnli']\n",
    "tasks = ['mrpc','qqp']\n",
    "\n",
    "dls_s, pred_heads, loss_funcs, metrics_s = [], [], [], []\n",
    "for task in tasks:\n",
    "  # multi_dls\n",
    "  dls_s.append(glue_dls[task])\n",
    "  # multi_model\n",
    "  pred_heads.append(SentencePredictHead(electra_config.hidden_size, TARG_VOC_SIZE[task]))    \n",
    "  # multi_loss_func\n",
    "  loss_funcs.append(CrossEntropyLossFlat() if task != 'stsb' else MSELossFlat())\n",
    "  # multi_metrics\n",
    "  metrics_s.append([eval(f'{metric}()') for metric in METRICS[task]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_head_model = MultiHeadModel(HF_ModelWrapper.from_pretrained(ElectraModel, 'google/electra-small-discriminator', pad_id=hf_tokenizer.pad_token_id, sep_id=hf_tokenizer.sep_token_id), \n",
    "                                  pred_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_learn = MultiTaskLearner(multi_dls=dls_s,\n",
    "                               opt_func=partial(Adam, eps=1e-6,),\n",
    "                               multi_model=multi_head_model,\n",
    "                               multi_loss_func=loss_funcs,\n",
    "                               task_weights=[0.5,0.5], # default as [1.] * number of tasks\n",
    "                               task_names=tasks,\n",
    "                               multi_metrics=metrics_s,\n",
    "                               splitter=partial(hf_electra_param_splitter,\n",
    "                                                num_hidden_layers=electra_config.num_hidden_layers,\n",
    "                                                outlayer_name='pred_heads'),\n",
    "                               lr=get_layer_lrs(3e-4,0.8,electra_config.num_hidden_layers),\n",
    "                               )#.to_fp16()\n",
    "\n",
    "multi_learn.fit(2, 3e-4)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "yKxetBkqfdgm",
    "MqtDnxK9ZYQP",
    "LFcM5MGaafFJ",
    "7cR6NmFsxH10",
    "n1vFihXdx7iQ",
    "pZS8owurxXUV",
    "admPAZ2M2uqO",
    "1NSoV-Np6utL"
   ],
   "name": "Finetune GLUE with fastai.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "007556af2af8413ca47aa5f7f725e68a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2d26c89a3d97493e911c52fa20cf79d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd8da3c0b2784f2094d3b0cfa744cf87",
      "placeholder": "​",
      "style": "IPY_MODEL_5b8f1e5172204ed58bd60972289b24a8",
      "value": " 29.0k/29.0k [00:00&lt;00:00, 39.1kB/s]"
     }
    },
    "5b8f1e5172204ed58bd60972289b24a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "65eee3543a9d46adbc8037995c3a69a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "71beed6de71c4aa2862ef33e21cc58bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8d4771f53c7046f1afe7e04a3a647a31": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9fc29a98d6be46e0974d1f0f7681d5c3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a07124360f4c4249a745891d83e719f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d4771f53c7046f1afe7e04a3a647a31",
      "max": 30329,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_007556af2af8413ca47aa5f7f725e68a",
      "value": 30329
     }
    },
    "a8b32129b9ab41d0895cb1ec445db9ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9fc29a98d6be46e0974d1f0f7681d5c3",
      "max": 28998,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_65eee3543a9d46adbc8037995c3a69a0",
      "value": 28998
     }
    },
    "ae0863b074ff4a1a959514881fe2802f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a8b32129b9ab41d0895cb1ec445db9ca",
       "IPY_MODEL_2d26c89a3d97493e911c52fa20cf79d9"
      ],
      "layout": "IPY_MODEL_e5d5d86746ec4e2298028c57ef775d84"
     }
    },
    "bd8da3c0b2784f2094d3b0cfa744cf87": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1d8bdd9c1a74bc18a103bc900589c2c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5d5d86746ec4e2298028c57ef775d84": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f26a4f6d9334465d9022ab2a3401035b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e1d8bdd9c1a74bc18a103bc900589c2c",
      "placeholder": "​",
      "style": "IPY_MODEL_71beed6de71c4aa2862ef33e21cc58bc",
      "value": " 30.3k/30.3k [00:00&lt;00:00, 392kB/s]"
     }
    },
    "f35afd9d13c240aba4e0619cca0199b7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f74af04bf4764b7888f0a45e37ce85c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a07124360f4c4249a745891d83e719f6",
       "IPY_MODEL_f26a4f6d9334465d9022ab2a3401035b"
      ],
      "layout": "IPY_MODEL_f35afd9d13c240aba4e0619cca0199b7"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}